{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8e695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "df = pd.read_csv(\"data/synthetic_em_data.csv\")\n",
    "X = df[[\"Time\", \"dBdt\"]].values\n",
    "y = df[[\"Depth\",\"Resistivity\"]].values\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdf48f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = EMModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd455fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.031776\n",
      "Epoch 100: Loss = 1.001517\n",
      "Epoch 200: Loss = 1.000582\n",
      "Epoch 300: Loss = 0.999698\n",
      "Epoch 400: Loss = 0.998958\n",
      "Epoch 500: Loss = 0.998225\n",
      "Epoch 600: Loss = 0.997430\n",
      "Epoch 700: Loss = 0.996786\n",
      "Epoch 800: Loss = 0.996324\n",
      "Epoch 900: Loss = 0.995831\n",
      "Epoch 1000: Loss = 0.995434\n",
      "Epoch 1100: Loss = 0.995097\n",
      "Epoch 1200: Loss = 0.994804\n",
      "Epoch 1300: Loss = 0.994582\n",
      "Epoch 1400: Loss = 0.994359\n",
      "Epoch 1500: Loss = 0.994193\n",
      "Epoch 1600: Loss = 0.994074\n",
      "Epoch 1700: Loss = 0.993964\n",
      "Epoch 1800: Loss = 0.993898\n",
      "Epoch 1900: Loss = 0.993865\n",
      "Epoch 2000: Loss = 0.993812\n",
      "Epoch 2100: Loss = 0.993779\n",
      "Epoch 2200: Loss = 0.993753\n",
      "Epoch 2300: Loss = 0.993730\n",
      "Epoch 2400: Loss = 0.993714\n",
      "Epoch 2500: Loss = 0.993720\n",
      "Epoch 2600: Loss = 0.993713\n",
      "Epoch 2700: Loss = 0.993675\n",
      "Epoch 2800: Loss = 0.993678\n",
      "Epoch 2900: Loss = 0.993645\n",
      "Epoch 3000: Loss = 0.993640\n",
      "Epoch 3100: Loss = 0.993636\n",
      "Epoch 3200: Loss = 0.993630\n",
      "Epoch 3300: Loss = 0.993611\n",
      "Epoch 3400: Loss = 0.993602\n",
      "Epoch 3500: Loss = 0.993636\n",
      "Epoch 3600: Loss = 0.993594\n",
      "Epoch 3700: Loss = 0.993603\n",
      "Epoch 3800: Loss = 0.993582\n",
      "Epoch 3900: Loss = 0.993570\n",
      "Epoch 4000: Loss = 0.993596\n",
      "Epoch 4100: Loss = 0.993559\n",
      "Epoch 4200: Loss = 0.993565\n",
      "Epoch 4300: Loss = 0.993614\n",
      "Epoch 4400: Loss = 0.993554\n",
      "Epoch 4500: Loss = 0.993556\n",
      "Epoch 4600: Loss = 0.993541\n",
      "Epoch 4700: Loss = 0.993536\n",
      "Epoch 4800: Loss = 0.993565\n",
      "Epoch 4900: Loss = 0.993557\n",
      "Epoch 5000: Loss = 0.993594\n",
      "Epoch 5100: Loss = 0.993532\n",
      "Epoch 5200: Loss = 0.993523\n",
      "Epoch 5300: Loss = 0.993534\n",
      "Epoch 5400: Loss = 0.993516\n",
      "Epoch 5500: Loss = 0.993526\n",
      "Epoch 5600: Loss = 0.993526\n",
      "Epoch 5700: Loss = 0.993506\n",
      "Epoch 5800: Loss = 0.993560\n",
      "Epoch 5900: Loss = 0.993503\n",
      "Epoch 6000: Loss = 0.993796\n",
      "Epoch 6100: Loss = 0.993497\n",
      "Epoch 6200: Loss = 0.993504\n",
      "Epoch 6300: Loss = 0.993489\n",
      "Epoch 6400: Loss = 0.993518\n",
      "Epoch 6500: Loss = 0.993487\n",
      "Epoch 6600: Loss = 0.993490\n",
      "Epoch 6700: Loss = 0.993511\n",
      "Epoch 6800: Loss = 0.993482\n",
      "Epoch 6900: Loss = 0.993476\n",
      "Epoch 7000: Loss = 0.993782\n",
      "Epoch 7100: Loss = 0.993474\n",
      "Epoch 7200: Loss = 0.993485\n",
      "Epoch 7300: Loss = 0.993466\n",
      "Epoch 7400: Loss = 0.993474\n",
      "Epoch 7500: Loss = 0.993541\n",
      "Epoch 7600: Loss = 0.993486\n",
      "Epoch 7700: Loss = 0.993469\n",
      "Epoch 7800: Loss = 0.993452\n",
      "Epoch 7900: Loss = 0.993457\n",
      "Epoch 8000: Loss = 0.993439\n",
      "Epoch 8100: Loss = 0.993462\n",
      "Epoch 8200: Loss = 0.993424\n",
      "Epoch 8300: Loss = 0.993425\n",
      "Epoch 8400: Loss = 0.993418\n",
      "Epoch 8500: Loss = 0.993474\n",
      "Epoch 8600: Loss = 0.993439\n",
      "Epoch 8700: Loss = 0.993398\n",
      "Epoch 8800: Loss = 0.993396\n",
      "Epoch 8900: Loss = 0.993400\n",
      "Epoch 9000: Loss = 0.993383\n",
      "Epoch 9100: Loss = 0.993382\n",
      "Epoch 9200: Loss = 0.993394\n",
      "Epoch 9300: Loss = 0.993370\n",
      "Epoch 9400: Loss = 0.993387\n",
      "Epoch 9500: Loss = 0.993361\n",
      "Epoch 9600: Loss = 0.993360\n",
      "Epoch 9700: Loss = 0.993351\n",
      "Epoch 9800: Loss = 0.993351\n",
      "Epoch 9900: Loss = 0.993360\n",
      "Epoch 9999: Loss = 0.993353\n"
     ]
    }
   ],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "EPOCHS = 10000\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    y_pred = model(X_train_t)\n",
    "    loss = loss_fn(y_pred, y_train_t)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 or epoch == 9999:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f151eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-194.07242  786.67914]\n"
     ]
    }
   ],
   "source": [
    "def predict_dbdt(time, dBdt):\n",
    "    inp = torch.tensor(scaler_X.transform([[time, dBdt]]), dtype=torch.float32)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(inp)\n",
    "    return scaler_y.inverse_transform(pred.numpy())[0][:2]\n",
    "\n",
    "print(predict_dbdt(1e-05, -5.60886297079976E-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved to models/em_model.pth\n"
     ]
    }
   ],
   "source": [
    "# !mkdir models\n",
    "# torch.save(model.state_dict(), \"models/em_model.pth\")\n",
    "# print(f\"Model Saved to models/em_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
